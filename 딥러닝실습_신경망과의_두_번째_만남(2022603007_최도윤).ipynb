{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnmcPOWxbQgu"
      },
      "source": [
        "by uramoon@kw.ac.kr <br>\n",
        "원본 출처: https://github.com/rickiepark/deep-learning-with-python-notebooks <a href=\"https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/LICENSE\">(MIT License)</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl8n95y_avHS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e390acb-6805-404e-c3d6-83fc6c70c804"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL0Fa8CzavHX"
      },
      "source": [
        "# 신경망과의 두 번째 만남\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 2장 1절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
        "\n",
        "----\n",
        "\n",
        "케라스 파이썬 라이브러리를 사용하여 손글씨 숫자 분류를 학습하는 구체적인 신경망 예제를 살펴보겠습니다. 케라스나 비슷한 라이브러리를 사용한 경험이 없다면 당장은 이 첫 번째 예제를 모두 이해하지 못할 것입니다. 아직 케라스를 설치하지 않았을지도 모릅니다. 괜찮습니다. 다음 장에서 이 예제를 하나하나 자세히 설명합니다. 코드가 좀 이상하거나 요술처럼 보이더라도 너무 걱정하지 마세요. 일단 시작해 보겠습니다.\n",
        "\n",
        "여기에서 풀려고 하는 문제는 흑백 손글씨 숫자 이미지(28x28 픽셀)를 10개의 범주(0에서 9까지)로 분류하는 것입니다. 머신 러닝 커뮤니티에서 고전으로 취급받는 데이터셋인 MNIST를 사용하겠습니다. 이 데이터셋은 머신 러닝의 역사만큼 오래되었고 많은 연구에 사용되었습니다. 이 데이터셋은 1980년대에 미국 국립표준기술연구소에서 수집한 6만 개의 훈련 이미지와 1만 개의 테스트 이미지로 구성되어 있습니다. MNIST 문제를 알고리즘이 제대로 작동하는지 확인하기 위한 딥러닝계의 ‘Hello World’라고 생각해도 됩니다. 머신 러닝 기술자가 되기까지 연구 논문이나 블로그 포스트 등에서 MNIST를 보고 또 보게 될 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPnVPmltavHY"
      },
      "source": [
        "MNIST 데이터셋은 넘파이 배열 형태로 케라스에 이미 포함되어 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCBjPiT9avHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf534139-a13d-4b81-c885-db0cb0acce86"
      },
      "source": [
        "# TODO: Keras에서 제공하는 MNIST 데이터셋 불러오기\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNoeRx8zavHY"
      },
      "source": [
        "`train_images`와 `train_labels`가 모델이 학습해야 할 훈련 세트를 구성합니다. 모델은 `test_images`와 `test_labels`로 구성된 테스트 세트에서 테스트될 것입니다. 이미지는 넘파이 배열로 인코딩되어 있고 레이블은 0에서부터 9까지의 숫자 배열입니다. 이미지와 레이블은 일대일 관계를 가집니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCi7plIavHb"
      },
      "source": [
        "작업 순서는 다음과 같습니다. 먼저 훈련 데이터 `train_images`와 `train_labels`를 네트워크에 주입합니다. 그러면 네트워크는 이미지와 레이블을 연관시킬 수 있도록 학습됩니다. 마지막으로 `test_images`에 대한 예측을 네트워크에게 요청합니다. 그리고 이 예측이 `test_labels`와 맞는지 확인할 것입니다.\n",
        "\n",
        "신경망을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAuPjlTTavHb"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(28 * 28,)))\n",
        "network.add(layers.Dense(512, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 네트워크의 구조 보기\n",
        "network.summary()"
      ],
      "metadata": {
        "id": "QIq6AO6EljdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7b1504e6-98a1-4272-f514-6fddd4b3f3a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YseI23eKavHb"
      },
      "source": [
        "신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 층입니다. 어떤 데이터가 들어가면 더 유용한 형태로 출력됩니다. 조금 더 구체적으로 층은 주어진 문제에 더 의미 있는 표현을 입력된 데이터로부터 추출합니다. 대부분의 딥러닝은 간단한 층을 연결하여 구성되어 있고, 점진적으로 데이터를 정제하는 형태를 띠고 있습니다. 딥러닝 모델은 데이터 정제 필터(층)가 연속되어 있는 데이터 프로세싱을 위한 여과기와 같습니다.\n",
        "\n",
        "이 예에서는 조밀하게 연결된 (또는 완전 연결된) 신경망 층인 `Dense` 층 2개가 연속되어 있습니다. 두 번째 (즉, 마지막) 층은 10개의 확률 점수가 들어 있는 배열(모두 더하면 1입니다)을 반환하는 소프트맥스 층입니다. 각 점수는 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률입니다.\n",
        "\n",
        "신경망이 훈련 준비를 마치기 위해서 컴파일 단계에 포함될 세 가지가 더 필요합니다:\n",
        "\n",
        "* 손실 함수 : 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 도와 줍니다.\n",
        "* 옵티마이저: 입력된 데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘입니다.\n",
        "* 훈련과 테스트 과정을 모니터링할 지표 : 여기에서는 정확도(정확히 분류된 이미지의 비율)만 고려하겠습니다.\n",
        "\n",
        "손실 함수와 옵티마이저의 정확한 목적은 이어지는 두 개의 장에서 자세히 설명하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvB6JTrxavHb"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikDaEzT2avHc"
      },
      "source": [
        "훈련을 시작하기 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 0과 1 사이로 스케일을 조정합니다. 예를 들어, 앞서 우리의 훈련 이미지는 `[0, 255]` 사이의 값인 `uint8` 타입의 `(60000, 28, 28)` 크기를 가진 배열로 저장되어 있습니다. 이 데이터를 0과 1 사이의 값을 가지는 `float32` 타입의 `(60000, 28 * 28)` 크기의 배열로 바꿉니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll4eb4WcavHc"
      },
      "source": [
        "# TODO: [0, 255]의 이차원 정수 배열로 표현된 이미지를\n",
        "# [0, 1]의 일차원 실수 배열로 변환하세요. (Normalization, Scaling or 정규화)\n",
        "\n",
        "norm_train_images = train_images.reshape((60000, 28 * 28))\n",
        "norm_train_images = norm_train_images.astype('float32')/255.0\n",
        "norm_test_images = test_images.reshape((10000,28*28))\n",
        "norm_test_images = norm_test_images.astype('float32')/255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kMzm3rYavHc"
      },
      "source": [
        "또한, 레이블을 범주형으로 인코딩해야 합니다. 이 단계는 3장에서 자세히 설명하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpXEeZ-lavHc"
      },
      "source": [
        "# TODO: 레이블을 범주형으로 변환\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "cat_train_labels = to_categorical(train_labels)\n",
        "cat_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMqek4L6avHc"
      },
      "source": [
        "이제 신경망을 훈련시킬 준비가 되었습니다. 케라스에서는 `fit` 메서드를 호출하여 훈련 데이터에 모델을 학습시킵니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RYOQNutavHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b273a0f-6762-444e-f69e-97d61b145b5d"
      },
      "source": [
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.4457\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9663 - loss: 0.1147\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9791 - loss: 0.0712\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0511\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d21cabf7b50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2-JZZPLavHd"
      },
      "source": [
        "훈련하는 동안 두 개의 정보가 출력됩니다. 훈련 데이터에 대한 네트워크의 손실과 정확도입니다.\n",
        "\n",
        "훈련 데이터에 대해 0.989(98.9%)의 정확도를 금방 달성합니다. 이제 테스트 세트에서도 모델이 잘 작동하는지 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFCyuCAvavHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dfbdbc-ab93-4889-fff0-a72a0b8ebc1a"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_wrMEkVavHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3157eac4-1556-4773-98ff-6cb0825db3af"
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.9804999828338623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEIgwx2savHd"
      },
      "source": [
        "테스트 세트의 정확도는 97.8%로 나왔습니다. 훈련 세트 정확도보다는 약간 낮습니다. 훈련 정확도와 테스트 정확도 사이의 차이는 과대적합 때문입니다. 이는 머신 러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향을 말합니다. 과대적합은 3장에서 자세하게 논의하겠습니다.\n",
        "\n",
        "이것으로 첫 번째 예제가 마무리되었습니다. 20줄 미만의 파이썬 코드로 손글씨 숫자를 분류하는 신경망을 만들고 훈련시켰습니다. 다음 장에서 여기서 보았던 코드 하나하나를 상세하게 설명하고 이들이 의미하는 바를 명확하게 설명하겠습니다. 이제 텐서, 신경망에 주입하는 데이터의 저장 형태, 층을 만들어주는 텐서 연산, 신경망을 훈련 샘플로부터 학습시키는 경사 하강법에 대해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r66ahJoBpuZB"
      },
      "source": [
        "## TODO 1: 은닉층의 유닛수\n",
        "1. 첫 번째 은닉층의 유닛수를 64로 바꾸면 테스트 데이터 정확도는?\n",
        "2. 첫 번째 은닉층의 유닛수를 1024로 바꾸면 테스트 데이터 정확도는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IDFygWMp_P3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb996c6-832a-42eb-da1e-e0a3e9412af7"
      },
      "source": [
        "# TODO: 64일 때 테스트 정확도 출력\n",
        "from tensorflow.keras import optimizers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(28 * 28,)))\n",
        "network.add(layers.Dense(64, activation='relu')) #TODO\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.6434\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.2069\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1543\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1211\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.1054\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1360\n",
            "test_acc: 0.965399980545044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: 1024일 때 테스트 정확도 출력\n",
        "network.add(layers.Dense(1024, activation='relu'))\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "id": "6TXiPlir0ZEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b2aedb-7390-40f3-847e-ff2d8570904d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.0902\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0800\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0714\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0631\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0560\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1002\n",
            "test_acc: 0.9750999808311462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUh9JOIWvENW"
      },
      "source": [
        "## TODO 2: 은닉층의 활성화 함수\n",
        "1. 첫 번째 은닉층의 활성화 함수를 sigmoid로 바꾸면 테스트 데이터 정확도는?\n",
        "2. 첫 번째 은닉층의 활성화 함수를 tanh로 바꾸면 테스트 데이터 정확도는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUQvr-vGvNb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec77b3d-3bd9-4af2-ff7c-bb6b55065edd"
      },
      "source": [
        "# TODO: sigmoid일 때 테스트 정확도 출력\n",
        "from tensorflow.keras import optimizers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(28 * 28,)))\n",
        "network.add(layers.Dense(512, activation='sigmoid'))#TODO\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8096 - loss: 0.7378\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9189 - loss: 0.2797\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.2309\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9465 - loss: 0.1864\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9555 - loss: 0.1515\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1585\n",
            "test_acc: 0.9602000117301941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: tanh일 때 테스트 정확도 출력\n",
        "network.add(layers.Dense(512, activation='tanh'))\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "id": "RWtdtR701RPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402d4cde-b0c3-46f5-bfa1-a1cc1cf2c919"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.0642\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0563\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0494\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0458\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0402\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0775\n",
            "test_acc: 0.9778000116348267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFBGsy7rvmef"
      },
      "source": [
        "## TODO 3: Softmax\n",
        "\n",
        "아래 코드블록을 사용하여 답변하세요.\n",
        "1. [-1, 0, 1]에서 softmax 결과 0이 선택될 확률은?\n",
        "2. [1, 2, 3]에서 softmax 결과 3이 선택될 확률은?\n",
        "3. [10, 20, 30]에서 softmax 결과 30이 선택될 확률은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU7fWLF9voWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac204523-74c4-4945-a76c-b93d399b96bb"
      },
      "source": [
        "# TODO: 위의 질문에 대한 답을 출력하세요.\n",
        "# Softmax 함수는 모든 범위의 실수 값들을 받아들여 확률로 변환 가능한 장점이 있습니다.\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "# 1번\n",
        "print(softmax([-1,0,1])[1])\n",
        "\n",
        "# 2번\n",
        "print(softmax([1,2,3])[2])\n",
        "\n",
        "# 3번\n",
        "print(softmax([10, 20, 30])[2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24472847105479764\n",
            "0.6652409557748218\n",
            "0.999954600070331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWfVyZ6zwWl6"
      },
      "source": [
        "## TODO 4: Optimizer\n",
        "https://keras.io/api/optimizers/sgd/\n",
        "1. optimizer에 SGD()를 썼을 때 테스트 정확도는?\n",
        "2. optimizer에 SGD(learning_rate=0.1, momentum=0.9, nesterov=True)를 썼을 때 테스트 정확도는?\n",
        "3. optimizer에 Adam()을 썼을 때 테스트 정확도는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRIYd7X54t0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6c3b87-b330-4f31-f9ad-07337732a3d3"
      },
      "source": [
        "# TODO: SGD()를 사용했을 때의 테스트 정확도 출력\n",
        "from tensorflow.keras import optimizers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(28 * 28,)))\n",
        "network.add(layers.Dense(512, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer=optimizers.SGD(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy']) #TODO\n",
        "\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6103 - loss: 1.5432\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.5680\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.4359\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8991 - loss: 0.3790\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.3480\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3633\n",
            "test_acc: 0.9129999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: SGD(learning_rate=0.1, momentum=0.9, nesterov=True)를 사용했을 때의 테스트 정확도 출력\n",
        "network.compile(optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "id": "at3KajAe14FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5cfae5-0475-4ddc-89ae-d0712fc8e054"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.2459\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.0888\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0560\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0377\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0248\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0781\n",
            "test_acc: 0.9822999835014343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Adam()을 사용했을 때의 테스트 정확도 출력\n",
        "network.compile(optimizer=optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "id": "L23hC8nm68S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f895f537-9990-4349-e5dc-d295738a7285"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0253\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0135\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0082\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0089\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0074\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0876\n",
            "test_acc: 0.9800000190734863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV9Fp7jmAnVC"
      },
      "source": [
        "## TODO 5: 정규화의 영향\n",
        "\n",
        "1. 이미지들을 정규화하지 않고 학습시켰을 때 테스트 정확도는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-jMqhf1AdRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06123851-7284-4c5b-a687-20b0e2385fc1"
      },
      "source": [
        "# TODO: [0, 1]로의 정규화 없이 이미지를 일차원 배열로 reshape만 수행했을 때의 테스트 정확도 출력\n",
        "conv_train_images = train_images.reshape((60000, 28 * 28))\n",
        "conv_test_images = test_images.reshape((10000,28*28))\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(28 * 28,)))\n",
        "network.add(layers.Dense(512, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(conv_train_images,cat_train_labels , epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(conv_test_images,cat_test_labels )\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 15.4584\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9510 - loss: 0.7357\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.4290\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9708 - loss: 0.3784\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9765 - loss: 0.2864\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9573 - loss: 0.8653\n",
            "test_acc: 0.9617000222206116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 6: 최적화\n",
        "\n",
        "1. 자유롭게 MLP (Multi-layer Perceptron)를 만들어서 Test 정확도를 98.2% 이상으로 만들어보세요. (층 추가 가능)"
      ],
      "metadata": {
        "id": "HV7c9PPv5c3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255.0\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255.0\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(28 * 28,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=25, batch_size=128, verbose=2, validation_split=0.2)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "Q7MTFakW38xC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfb0f08-fb90-42be-acde-dbcc4f98ec95"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9076 - loss: 0.3053 - val_accuracy: 0.9615 - val_loss: 0.1255\n",
            "Epoch 2/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9640 - loss: 0.1210 - val_accuracy: 0.9677 - val_loss: 0.1019\n",
            "Epoch 3/25\n",
            "375/375 - 5s - 13ms/step - accuracy: 0.9732 - loss: 0.0866 - val_accuracy: 0.9758 - val_loss: 0.0823\n",
            "Epoch 4/25\n",
            "375/375 - 6s - 16ms/step - accuracy: 0.9783 - loss: 0.0684 - val_accuracy: 0.9772 - val_loss: 0.0769\n",
            "Epoch 5/25\n",
            "375/375 - 10s - 27ms/step - accuracy: 0.9821 - loss: 0.0558 - val_accuracy: 0.9775 - val_loss: 0.0815\n",
            "Epoch 6/25\n",
            "375/375 - 10s - 25ms/step - accuracy: 0.9846 - loss: 0.0472 - val_accuracy: 0.9788 - val_loss: 0.0803\n",
            "Epoch 7/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9863 - loss: 0.0418 - val_accuracy: 0.9756 - val_loss: 0.0871\n",
            "Epoch 8/25\n",
            "375/375 - 9s - 24ms/step - accuracy: 0.9882 - loss: 0.0359 - val_accuracy: 0.9779 - val_loss: 0.0833\n",
            "Epoch 9/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9884 - loss: 0.0359 - val_accuracy: 0.9761 - val_loss: 0.0893\n",
            "Epoch 10/25\n",
            "375/375 - 9s - 24ms/step - accuracy: 0.9905 - loss: 0.0283 - val_accuracy: 0.9794 - val_loss: 0.0836\n",
            "Epoch 11/25\n",
            "375/375 - 6s - 16ms/step - accuracy: 0.9896 - loss: 0.0314 - val_accuracy: 0.9787 - val_loss: 0.0827\n",
            "Epoch 12/25\n",
            "375/375 - 5s - 13ms/step - accuracy: 0.9917 - loss: 0.0255 - val_accuracy: 0.9772 - val_loss: 0.0969\n",
            "Epoch 13/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9922 - loss: 0.0252 - val_accuracy: 0.9797 - val_loss: 0.0895\n",
            "Epoch 14/25\n",
            "375/375 - 5s - 13ms/step - accuracy: 0.9925 - loss: 0.0224 - val_accuracy: 0.9797 - val_loss: 0.0847\n",
            "Epoch 15/25\n",
            "375/375 - 5s - 14ms/step - accuracy: 0.9922 - loss: 0.0241 - val_accuracy: 0.9808 - val_loss: 0.0909\n",
            "Epoch 16/25\n",
            "375/375 - 10s - 26ms/step - accuracy: 0.9929 - loss: 0.0228 - val_accuracy: 0.9804 - val_loss: 0.0969\n",
            "Epoch 17/25\n",
            "375/375 - 6s - 16ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9802 - val_loss: 0.0893\n",
            "Epoch 18/25\n",
            "375/375 - 9s - 24ms/step - accuracy: 0.9937 - loss: 0.0196 - val_accuracy: 0.9807 - val_loss: 0.0976\n",
            "Epoch 19/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9940 - loss: 0.0178 - val_accuracy: 0.9787 - val_loss: 0.1043\n",
            "Epoch 20/25\n",
            "375/375 - 11s - 30ms/step - accuracy: 0.9942 - loss: 0.0184 - val_accuracy: 0.9802 - val_loss: 0.0904\n",
            "Epoch 21/25\n",
            "375/375 - 8s - 21ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9809 - val_loss: 0.0950\n",
            "Epoch 22/25\n",
            "375/375 - 6s - 17ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.9801 - val_loss: 0.0990\n",
            "Epoch 23/25\n",
            "375/375 - 5s - 13ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.9796 - val_loss: 0.1051\n",
            "Epoch 24/25\n",
            "375/375 - 6s - 15ms/step - accuracy: 0.9947 - loss: 0.0177 - val_accuracy: 0.9802 - val_loss: 0.0988\n",
            "Epoch 25/25\n",
            "375/375 - 10s - 26ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9812 - val_loss: 0.0954\n",
            "Test Accuracy: 98.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRzvurdzBZf1"
      },
      "source": [
        "##TODO 7: 마무리\n",
        "\n",
        "오늘 실습에서 인공신경망의 성능에 영향을 준 요인들을 나열해보세요."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A: 데이터 양, 데이터 정규화, 데이터 최적화, 모델 활성화 함수, Softmax, Optimizer, SGD, Adam RMSprop, EPpochs, 은닉층과 유닛의 개수"
      ],
      "metadata": {
        "id": "Nw1JBoMT8Vdm"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}